{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy\n",
    "import math\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import get_laplacian\n",
    "data = dataset[0]\n",
    "L = get_laplacian(data.edge_index, normalization=\"sym\")\n",
    "L = torch.sparse.FloatTensor(L[0], L[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Sizes of variables</b>: </center>\n",
    "$$L \\in M^{2708\\times 2708}$$\n",
    "$$Features \\in R^{2708\\times 1433}$$\n",
    "$$Labels \\in N^{2708}$$\n",
    "<center>Number of classes: 7</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheb-Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    _, pred = model(data.x, L).max(dim=1)\n",
    "    correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    acc = correct / data.test_mask.sum().item()\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_Convolution_Chebychev(nn.Module):\n",
    "        \n",
    "        def __init__(self, F_in, F_out, K):\n",
    "            super(Graph_Convolution_Chebychev, self).__init__()\n",
    "            self.F_in = F_in\n",
    "            self.F_out = F_out\n",
    "            self.weight = Parameter(torch.FloatTensor(K, F_in, F_out))\n",
    "            self.bias = Parameter(torch.FloatTensor(F_out))\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "            self.weight.data.uniform_(-stdv, stdv)\n",
    "            self.bias.data.fill_(0.0)\n",
    "        \n",
    "        def forward(self, x, L):\n",
    "            Tx_0 = x.contiguous()\n",
    "            out = torch.matmul(Tx_0, self.weight[0])\n",
    "\n",
    "            if self.weight.size(0) > 1:\n",
    "                Tx_1 = torch.spmm(L, x)\n",
    "                out = out + torch.matmul(Tx_1, self.weight[1])\n",
    "\n",
    "            for k in range(2, self.weight.size(0)):\n",
    "                Tx_2 = 2 * torch.spmm(L, Tx_1) - Tx_0\n",
    "                out = out + torch.matmul(Tx_2, self.weight[k])\n",
    "                Tx_0, Tx_1 = Tx_1, Tx_2\n",
    "\n",
    "            if self.bias is not None:\n",
    "                out = out + self.bias\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chebychev_convolutional_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, net_parameters):\n",
    "        super(Chebychev_convolutional_network, self).__init__()\n",
    "\n",
    "        self.F_in, self.F_out, self.K, self.dropout = net_parameters\n",
    "        self.GCN1 = Graph_Convolution_Chebychev(self.F_in, 20, K)\n",
    "        self.GCN2 = Graph_Convolution_Chebychev(20, 7, K)\n",
    "        \n",
    "        self.FC1 = nn.Linear(50, 128)\n",
    "        scale = 1. / math.sqrt(self.FC1.weight.size(1))\n",
    "        self.FC1.weight.data.uniform_(-scale, scale)\n",
    "        self.FC1.bias.data.fill_(0.0)\n",
    "        self.FC2 = nn.Linear(128, 7)\n",
    "        scale = 1. / math.sqrt(self.FC2.weight.size(1))\n",
    "        self.FC2.weight.data.uniform_(-scale, scale)\n",
    "        self.FC2.bias.data.fill_(0.0)\n",
    "        \n",
    "    def forward(self, x, L):\n",
    "        x = self.GCN1(x, L)\n",
    "        x = F.relu(x)\n",
    "        # x = self.graph_max_pool(x, 4)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.GCN2(x, L)\n",
    "        # x = self.graph_max_pool(x, 4)\n",
    "        # x = x.view(-1, self.FC1Fin)\n",
    "        # x = self.FC1(x)\n",
    "        # x = F.relu(x)\n",
    "        # x  = F.dropout(x, self.dropout, training=self.training)\n",
    "        # x = self.FC2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)  \n",
    "    \n",
    "    def loss(self, y, y_target, l2_regularization):\n",
    "    \n",
    "        loss = nn.CrossEntropyLoss()(y,y_target)\n",
    "\n",
    "        l2_loss = 0.0\n",
    "        for param in self.parameters():\n",
    "            data = param* param\n",
    "            l2_loss += data.sum()\n",
    "           \n",
    "        loss += 0.5* l2_regularization* l2_loss\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1090\n"
     ]
    }
   ],
   "source": [
    "F_in = 1433\n",
    "F_out = 7\n",
    "K = 2\n",
    "dropout = 0.2\n",
    "net_parameters = [F_in, F_out, K, dropout]\n",
    "\n",
    "cheb_net = Chebychev_convolutional_network(net_parameters)\n",
    "optimizer_cheb = optim.Adam(cheb_net.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test(cheb_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [19:34<00:00, 34.06it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_history = np.zeros(40000) \n",
    "\n",
    "for epoch in tqdm.trange(40000): \n",
    "  \n",
    "    outputs = cheb_net(data.x, L) # Usiamo tutto il dataset\n",
    "    loss = cheb_net.loss(outputs[data.train_mask], data.y[data.train_mask], 5e-4) # Mascheriamo sulla parte di training\n",
    "    loss.backward()\n",
    "    optimizer_cheb.step()\n",
    "    optimizer_cheb.zero_grad()\n",
    "\n",
    "    loss_history[epoch] = loss.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3110\n",
      "tensor(0.0155, grad_fn=<AddBackward0>)\n",
      "1.9645023345947266\n"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.show()\n",
    "test(cheb_net)\n",
    "print(loss)\n",
    "print(loss_history[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pytorch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    acc = correct / data.test_mask.sum().item()\n",
    "    print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChebNet_pytorch_geometric(torch.nn.Module):\n",
    "    def __init__(self, dataset, K):\n",
    "        super(ChebNet_pytorch_geometric, self).__init__()\n",
    "        self.conv1 = ChebConv(dataset.num_features, 20, K)\n",
    "        self.conv2 = ChebConv(20, 7, K)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheb_net = ChebNet_pytorch_geometric(data, 2)\n",
    "optimizer = optim.Adam(cheb_net.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test(cheb_net)\n",
    "\n",
    "loss_history = np.zeros(1000) \n",
    "\n",
    "for epoch in tqdm.trange(1000): \n",
    "  \n",
    "    outputs = cheb_net(data) # Usiamo tutto il dataset\n",
    "    loss = criterion(outputs[data.train_mask], data.y[data.train_mask]) # Mascheriamo sulla parte di training\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_history[epoch] = loss.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.show()\n",
    "test(cheb_net)\n",
    "print(loss)\n",
    "print(loss_history[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
